# Plan and Manage an Azure AI Solution

## Azure AI Services Overview

### Azure AI Services & Foundry

Azure's AI offerings include pre-built AI models (formerly Cognitive Services) for vision, language, speech, etc., and the newer Azure AI Foundry platform. Azure AI Foundry (recently renamed Microsoft Foundry) is a unified PaaS for AI apps, unifying models, agents, and tools under one platform with enterprise-ready features (RBAC, monitoring, etc.).

It provides a "hub" and "project" structure to manage resources and models, with both a classic and new portal experience for different needs. Azure AI Foundry integrates multiple model providers (Azure OpenAI, open-source models) under a consistent API and management plane.

### Azure AI Foundry

Azure AI Foundry streamlines building AI applications by providing a unified platform for:

- **Hub and Project Structure**: Create a Foundry Hub (Azure resource) and then Foundry Projects within it, which group models and agents for your solution
- **Model Catalog**: Includes over 10,000 models, including OpenAI models and many open-source models (Hugging Face, etc.)
- **Model Router**: Can automatically select the best model for a given prompt (optimizing quality vs cost) if enabled
- **Enterprise Features**: RBAC, monitoring, and integration with Azure ecosystem

## Selecting the Right Azure AI Service

Choose Azure AI services based on the solution domain:

### Generative AI
Use **Azure OpenAI Service** (GPT-3.5, GPT-4 models for text; Codex for code; DALL·E for image generation) for AI content generation. Azure OpenAI provides enterprise-grade security, compliance, and integration into Azure ecosystem while giving access to OpenAI's advanced models.

### Computer Vision
- **Azure AI Vision** for image analysis (object detection, tagging, OCR)
- **Azure AI Video Indexer** for video insights
- **Custom Vision** for custom image recognition (classification or object detection models)

### Natural Language Processing (NLP)
- **Azure AI Language services** for text analytics (sentiment analysis, key phrase extraction, entity recognition, language detection, PII detection)
- **Azure AI Translator** for translation of text/documents
- **Conversational Language Understanding** (formerly LUIS, now CLU) to build custom language models (intents, entities)
- **Question Answering** for custom QnA knowledge base

### Speech
**Azure AI Speech** for speech-to-text, text-to-speech, speech translation, and custom speech recognition or custom voice fonts.

### Information Extraction
- **Azure AI Document Intelligence** (formerly Form Recognizer) to extract structured data from forms/documents
- **Azure AI Content Understanding** for multimodal data extraction – processes documents, images, audio, video with generative AI to produce structured insights
- **Azure AI Search** (formerly Cognitive Search) for search-based knowledge mining

## Creating Azure AI Resources

Deploy Azure AI services via:
- Azure portal
- Azure CLI
- ARM/Bicep templates

When using **Azure AI Foundry**, you typically create a Foundry Hub resource (the top-level Azure resource) and then create Foundry Projects within it. Ensure the resource is in a region that supports the needed features (some AI services are region-specific).

### AI Model Deployment Options

**For Azure OpenAI**: Deploy a model (e.g., GPT-4 or ChatGPT) to an endpoint within your OpenAI resource for usage (creates a deployment with a name, e.g., "gpt-4" deployment).

**For Custom Vision**: Train a model in the Custom Vision portal and publish it to a prediction endpoint on your Azure resource for consumption.

**For Azure AI Document Intelligence**: After training a custom form model you publish the model (assigning it an ID) so it can be called via the API.

**Container Deployment**: Many cognitive services support container deployment for on-premises or edge use. Azure Cognitive Services offers container images for vision, language, and speech tasks so you can run them locally when needed.

## SDKs and APIs

Azure AI services provide:
- REST endpoints
- Client SDKs (in languages like Python, C#, JavaScript, Java)

Examples:
- azure-ai-vision
- azure-ai-language
- azure-cognitiveservices-speech
- Azure OpenAI has REST APIs for completions, chat, and image generation

Using the SDK simplifies tasks like authentication and request/response handling.

## Authentication and Security

### API Keys
By default, Azure AI services use API keys for authentication (each resource provides keys). Protect these keys – store them in Azure Key Vault or use Azure AI's integration with Azure Key Vault to manage credentials.

### Azure AD Authentication
Many Azure AI services also support Azure AD authentication via managed identities or service principals, so applications can call the service without handling raw keys. For example, Azure OpenAI supports Azure AD OAuth tokens in lieu of an API key for certain endpoints.

**Best Practices**:
- Always follow the principle of least privilege
- Consider resource isolation (e.g., restrict network access to cognitive service resources with virtual network integration if required)
- Enable Customer Managed Keys (CMK) for cognitive services if you need to control encryption keys for data at rest

## Cost Management and Monitoring

### Monitoring Azure AI Resources

Use Azure Monitor metrics and logs:

**Metrics**: Azure AI services emit metrics like:
- Number of calls
- Latency
- Errors
- Resource-specific metrics (e.g., Azure OpenAI tracks tokens used, request count, and throttling occurrences)

Set up alerts on these metrics (e.g., if calls approach a quota limit).

**Logs**: Use Azure Monitor Logs or the built-in diagnostic settings to capture detailed logs of operations. Some services (like Azure AI OpenAI) provide logs of prompts/responses via diagnostic logging for auditing.

### Cost Management

Understand pricing models:
- Azure AI services often charge per 1,000 transactions or per hour for reserved capacity
- Azure OpenAI charges per input/output token for each model

**Cost Control Strategies**:
- Use budgets and cost alerts
- The Cost Management blade can show spending on each service
- Consider setting call rate limits
- Use tiers that fit your usage (some services offer free tiers or cheaper pricing for bulk usage like reserved capacity or batch processing)

**Responsible AI Monitoring**: Use Responsible AI dashboards or logging to monitor for problematic outputs (Azure AI services offer responsible AI insights logs – e.g., content safety results of each call).

## CI/CD Integration

Integrate Azure AI services into deployment pipelines to automate provisioning and updates:

**Infrastructure as Code**:
- Use ARM templates or Terraform to create resources (e.g., deploy Azure AI Search service, or an Azure OpenAI resource with certain model deployments)

**Automate Model Training and Deployment**:
- With Custom Vision or Form Recognizer, use their SDKs in a pipeline to train models with new data and publish them
- Azure AI Foundry projects can be managed via CLI/PowerShell or the Foundry REST API as part of DevOps pipelines

**Testing in Pipeline**:
- Include testing of AI components in your pipeline – e.g., run a test query against a deployed model in a staging environment to ensure it's operational

## Responsible AI Planning

Plan your solution to meet Microsoft's Responsible AI principles: fairness, reliability & safety, privacy & security, inclusiveness, transparency, and accountability.

### Content Moderation

If your solution processes user-generated content (images, text, etc.), incorporate **Azure AI Content Safety** for text and image moderation. Azure AI Content Safety provides multimodal content filtering to detect hate, sexual, violent, or self-harm content and assign severity scores. Use it to screen user inputs or AI outputs.

### Content Filters & Blocklists

**Azure OpenAI** (in Foundry) includes built-in content filters that automatically block or modify responses containing disallowed content. You can configure custom blocklists of terms that the AI should not output or should treat as sensitive. This helps enforce domain-specific banned phrases.

### Prompt Shield

Azure's **Prompt Shield** is a protection against prompt injection or user attempts to make the model ignore safeguards. It detects when a prompt tries to jailbreak the model (e.g., "ignore previous instructions") and blocks or alters such inputs.

Prompt Shield helps prevent harmful behavior by ensuring the model cannot be easily tricked into violating policies. Combine this with **Harmful Content Detection** – Azure Content Safety's classifiers can flag self-harm or violence-related outputs.

### Transparency & Human Oversight

- Log the AI's decisions and outputs for review (provide explanations if possible)
- For critical scenarios, keep a human in the loop to review AI outputs
- Clearly inform users when they are interacting with an AI and what its limitations are (e.g., via disclaimers)

### Governance

Establish a responsible AI governance framework:
- Define who will review model performance and ethical considerations
- Define how you will handle appeals or issues
- Define how models are tested for biases or errors

Ensure you regularly update models and datasets to address fairness and accuracy. Use tools like Azure's Responsible AI Dashboard or Fairlearn for bias detection in models (especially relevant if training custom models).

[↑](#content)
